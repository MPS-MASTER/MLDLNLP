{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization,LSTM, Reshape, SimpleRNN\n",
    "from keras.layers.recurrent import GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = string.ascii_lowercase+\"0123456789\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcdefghijklmnopqrstuvwxyz0123456789'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = os.listdir(\"samples/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('yyn57.png', 1070)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_images[-1], len(all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data():\n",
    "    \n",
    "    inp_x = np.zeros((len(all_images), 50,200,1))\n",
    "    inp_y = np.zeros((len(all_images), 5,len(characters)))\n",
    "    for idx, image in enumerate(all_images):\n",
    "        # ----------------prepare input container\n",
    "        \n",
    "        \n",
    "        img = cv2.imread(\"samples/\"+image, cv2.IMREAD_GRAYSCALE)\n",
    "        #print(np.max(img))\n",
    "        #plt.imshow(img)\n",
    "        \n",
    "        # ---------------------Scale images --------------\n",
    "        \n",
    "        img = img/255.0\n",
    "        \n",
    "        image_txt = image[:-4]\n",
    "        target_oht = np.zeros((5,len(characters)))\n",
    "        if(len(image_txt)<6):\n",
    "            img = np.reshape(img, (50,200,1))\n",
    "            inp_x[idx] = img\n",
    "            \n",
    "             # ------------------Define targets and code them using OneHotEncoding\n",
    "            target_oht = np.zeros((5,len(characters)))\n",
    "            for k, char in enumerate(image_txt):\n",
    "                target_oht[k, characters.find(char)] = 1\n",
    "            inp_y[idx] = target_oht\n",
    "    return inp_x, inp_y\n",
    "        \n",
    "               \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1070, 50, 200, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1070, 5, 36)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = X[:900]\n",
    "train_y = Y[:900]\n",
    "test_x = X[900:]\n",
    "test_y = Y[900:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model():\n",
    "    model.add(Conv2D(64, (3,3), input_shape = (50,200,1) ,padding = 'same', activation = 'tanh'))\n",
    "    #model.add(Dropout(.5))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size = (1,1),padding ='same'))\n",
    "    model.add(Conv2D(64, (3,3), activation = 'tanh', padding = 'same',))\n",
    "    #model.add(Dropout(.3))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size =(1,1),padding ='same'))\n",
    "    model.add(Conv2D(64, (3,3), activation = 'tanh', padding = 'same'))\n",
    "    #model.add(Dropout(.1))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size = (3,2),padding ='same'))\n",
    "    model.add(Conv2D(32, (3,3), activation = 'tanh', padding = 'same'))\n",
    "  \n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size = (2,2),padding ='same'))\n",
    "    model.add(Conv2D(32, (3,3), activation = 'tanh', padding = 'same'))\n",
    "    model.add(MaxPooling2D(pool_size = (2,1),padding ='same'))\n",
    "    print(model.output_shape)\n",
    "    model.add(Reshape((model.output_shape[1], model.output_shape[2]*model.output_shape[3])))\n",
    "    print(model.output_shape)\n",
    "    #model.add(LSTM(50, batch_input_shape=(2,5,36),stateful = True, return_sequences = True))\n",
    "    model.add(SimpleRNN(50, return_sequences = True,activation = 'relu'))\n",
    "    model.add(SimpleRNN(50, return_sequences = True,activation = 'relu'))\n",
    "    model.add(SimpleRNN(50, return_sequences = True,activation = 'relu'))\n",
    "    \n",
    "\n",
    "\n",
    "    model.add(Dense(36, activation = \"softmax\"))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "   \n",
    "    return model\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 5, 50, 32)\n",
      "(None, 5, 1600)\n"
     ]
    }
   ],
   "source": [
    "model =prepare_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 50, 200, 64)       640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 50, 200, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 50, 200, 64)       36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 50, 200, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 50, 200, 64)       36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 17, 100, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 17, 100, 32)       18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 9, 50, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 9, 50, 32)         9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 5, 50, 32)         0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 5, 1600)           0         \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 5, 50)             82550     \n",
      "_________________________________________________________________\n",
      "simple_rnn_2 (SimpleRNN)     (None, 5, 50)             5050      \n",
      "_________________________________________________________________\n",
      "simple_rnn_3 (SimpleRNN)     (None, 5, 50)             5050      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5, 36)             1836      \n",
      "=================================================================\n",
      "Total params: 196,694\n",
      "Trainable params: 196,694\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(170, 5, 36)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape\n",
    "train_y.shape\n",
    "test_x.shape\n",
    "test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 900 samples, validate on 170 samples\n",
      "Epoch 1/50\n",
      "900/900 [==============================] - 18s 20ms/step - loss: 3.3692 - accuracy: 0.0602 - val_loss: 3.3616 - val_accuracy: 0.0776\n",
      "Epoch 2/50\n",
      "900/900 [==============================] - 4s 5ms/step - loss: 3.0303 - accuracy: 0.0971 - val_loss: 3.3069 - val_accuracy: 0.0576\n",
      "Epoch 3/50\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 2.9151 - accuracy: 0.0944 - val_loss: 3.3254 - val_accuracy: 0.0788\n",
      "Epoch 4/50\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 2.8077 - accuracy: 0.1289 - val_loss: 3.3277 - val_accuracy: 0.0776\n",
      "Epoch 5/50\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 2.6623 - accuracy: 0.1691 - val_loss: 3.2729 - val_accuracy: 0.1141\n",
      "Epoch 6/50\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 2.4524 - accuracy: 0.2162 - val_loss: 3.2733 - val_accuracy: 0.1353\n",
      "Epoch 7/50\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 2.2514 - accuracy: 0.2560 - val_loss: 3.4663 - val_accuracy: 0.1682\n",
      "Epoch 8/50\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 2.0616 - accuracy: 0.3098 - val_loss: 3.5583 - val_accuracy: 0.1871\n",
      "Epoch 9/50\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 1.8739 - accuracy: 0.3611 - val_loss: 3.4984 - val_accuracy: 0.2459\n",
      "Epoch 10/50\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 1.7393 - accuracy: 0.4093 - val_loss: 3.5484 - val_accuracy: 0.2259\n",
      "Epoch 11/50\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 1.6248 - accuracy: 0.4396 - val_loss: 3.8029 - val_accuracy: 0.2247\n",
      "Epoch 12/50\n",
      "900/900 [==============================] - 4s 5ms/step - loss: 1.5034 - accuracy: 0.4871 - val_loss: 3.5672 - val_accuracy: 0.2894\n",
      "Epoch 13/50\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 1.3729 - accuracy: 0.5329 - val_loss: 3.7348 - val_accuracy: 0.2918\n",
      "Epoch 14/50\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 1.2201 - accuracy: 0.5829 - val_loss: 3.9481 - val_accuracy: 0.2988\n",
      "Epoch 15/50\n",
      "900/900 [==============================] - 4s 5ms/step - loss: 1.1695 - accuracy: 0.5958 - val_loss: 3.9384 - val_accuracy: 0.2824\n",
      "Epoch 16/50\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 1.1185 - accuracy: 0.6267 - val_loss: 3.7696 - val_accuracy: 0.3600\n",
      "Epoch 17/50\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 1.0040 - accuracy: 0.6573 - val_loss: 3.9106 - val_accuracy: 0.3729\n",
      "Epoch 18/50\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 0.9168 - accuracy: 0.6876 - val_loss: 3.9288 - val_accuracy: 0.3835\n",
      "Epoch 19/50\n",
      "900/900 [==============================] - 4s 5ms/step - loss: 0.8305 - accuracy: 0.7216 - val_loss: 4.1751 - val_accuracy: 0.3212\n",
      "Epoch 20/50\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 0.8207 - accuracy: 0.7269 - val_loss: 4.0548 - val_accuracy: 0.3776\n",
      "Epoch 21/50\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 0.8262 - accuracy: 0.7131 - val_loss: 4.1174 - val_accuracy: 0.3706\n",
      "Epoch 22/50\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 0.7119 - accuracy: 0.7627 - val_loss: 4.0774 - val_accuracy: 0.3847\n",
      "Epoch 23/50\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 0.6292 - accuracy: 0.7893 - val_loss: 4.0788 - val_accuracy: 0.4235\n",
      "Epoch 24/50\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 0.5493 - accuracy: 0.8247 - val_loss: 4.1635 - val_accuracy: 0.4141\n",
      "Epoch 25/50\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 0.5144 - accuracy: 0.8407 - val_loss: 4.3179 - val_accuracy: 0.3976\n",
      "Epoch 26/50\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 0.4882 - accuracy: 0.8469 - val_loss: 4.2561 - val_accuracy: 0.4247\n",
      "Epoch 27/50\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 0.4865 - accuracy: 0.8424 - val_loss: 4.3179 - val_accuracy: 0.3988\n",
      "Epoch 28/50\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 0.4111 - accuracy: 0.8751 - val_loss: 4.3199 - val_accuracy: 0.4176\n",
      "Epoch 29/50\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 0.3759 - accuracy: 0.8891 - val_loss: 4.3195 - val_accuracy: 0.4176\n",
      "Epoch 30/50\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 0.3353 - accuracy: 0.9076 - val_loss: 4.3124 - val_accuracy: 0.4118\n",
      "Epoch 31/50\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 0.3028 - accuracy: 0.9156 - val_loss: 4.4177 - val_accuracy: 0.4188\n",
      "Epoch 32/50\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 0.2734 - accuracy: 0.9296 - val_loss: 4.3984 - val_accuracy: 0.4341\n",
      "Epoch 33/50\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 0.2616 - accuracy: 0.9244 - val_loss: 4.4834 - val_accuracy: 0.4106\n",
      "Epoch 34/50\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 0.2417 - accuracy: 0.9371 - val_loss: 4.4140 - val_accuracy: 0.4306\n",
      "Epoch 35/50\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 0.2139 - accuracy: 0.9451 - val_loss: 4.3542 - val_accuracy: 0.4471\n",
      "Epoch 36/50\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 0.2052 - accuracy: 0.9464 - val_loss: 4.3545 - val_accuracy: 0.4506\n",
      "Epoch 37/50\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 0.1733 - accuracy: 0.9607 - val_loss: 4.5295 - val_accuracy: 0.4376\n",
      "Epoch 38/50\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 0.1552 - accuracy: 0.9667 - val_loss: 4.4755 - val_accuracy: 0.4400\n",
      "Epoch 39/50\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 0.1460 - accuracy: 0.9649 - val_loss: 4.5573 - val_accuracy: 0.4306\n",
      "Epoch 40/50\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 0.1303 - accuracy: 0.9740 - val_loss: 4.4766 - val_accuracy: 0.4600\n",
      "Epoch 41/50\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 0.1335 - accuracy: 0.9716 - val_loss: 4.5949 - val_accuracy: 0.4435\n",
      "Epoch 42/50\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 0.1239 - accuracy: 0.9729 - val_loss: 4.5597 - val_accuracy: 0.4447\n",
      "Epoch 43/50\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 0.1287 - accuracy: 0.9718 - val_loss: 4.5656 - val_accuracy: 0.4482\n",
      "Epoch 44/50\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 0.1487 - accuracy: 0.9609 - val_loss: 4.7377 - val_accuracy: 0.4365\n",
      "Epoch 45/50\n",
      "900/900 [==============================] - 5s 5ms/step - loss: 0.3290 - accuracy: 0.8947 - val_loss: 4.8293 - val_accuracy: 0.4118\n",
      "Epoch 46/50\n",
      "900/900 [==============================] - 4s 5ms/step - loss: 0.3603 - accuracy: 0.8840 - val_loss: 4.8733 - val_accuracy: 0.4165\n",
      "Epoch 47/50\n",
      "900/900 [==============================] - 5s 6ms/step - loss: 0.2806 - accuracy: 0.9107 - val_loss: 4.5931 - val_accuracy: 0.4518\n",
      "Epoch 48/50\n",
      "900/900 [==============================] - 5s 6ms/step - loss: 0.1885 - accuracy: 0.9449 - val_loss: 4.7704 - val_accuracy: 0.4376\n",
      "Epoch 49/50\n",
      "900/900 [==============================] - 5s 6ms/step - loss: 0.1223 - accuracy: 0.9702 - val_loss: 4.5678 - val_accuracy: 0.4565\n",
      "Epoch 50/50\n",
      "900/900 [==============================] - 5s 6ms/step - loss: 0.0902 - accuracy: 0.9829 - val_loss: 4.5767 - val_accuracy: 0.4729\n"
     ]
    }
   ],
   "source": [
    "#model = create_model()\n",
    "hist = model.fit(train_x, train_y, batch_size=32, epochs=50,verbose=1, validation_data=(test_x, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 0s 2ms/step\n",
      "Test Loss and accuracy: [4.576726464664235, 0.47294119000434875]\n"
     ]
    }
   ],
   "source": [
    "score= model.evaluate(test_x,test_y,verbose=1)\n",
    "print('Test Loss and accuracy:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to predict captcha\n",
    "def predict(filepath):\n",
    "    img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
    "    #print(\"img\",img.shape)\n",
    "    if(img is not None):\n",
    "        img = cv2.resize(img, (200,50))\n",
    "    if img is not None:\n",
    "        img = img / 255.0\n",
    "    else:\n",
    "        print(\"Not detected\");\n",
    "    res = np.array(model.predict(img[np.newaxis, :, :, np.newaxis]))\n",
    "    ans = np.reshape(res, (5, 36))\n",
    "    l_ind = []\n",
    "    probs = []\n",
    "    for a in ans:\n",
    "        l_ind.append(np.argmax(a))\n",
    "        #probs.append(np.max(a))\n",
    "\n",
    "    capt = ''\n",
    "    for l in l_ind:\n",
    "        capt += characters[l]\n",
    "    return capt#, sum(probs) / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8n5p3\n",
      "f2m8n\n",
      "dce8y\n",
      "3eny7\n",
      "npxb7\n",
      "66gmg\n"
     ]
    }
   ],
   "source": [
    "#model.evaluate(X_test, [y_test[0], y_test[1], y_test[2], y_test[3], y_test[4]])\n",
    "print(predict('samples/8n5p3.png'))\n",
    "print(predict('samples/f2m8n.png'))\n",
    "print(predict('samples/dce8y.png'))\n",
    "print(predict('samples/3eny7.png'))\n",
    "print(predict('samples/npxb7.png'))\n",
    "print(predict('test/captcha.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
